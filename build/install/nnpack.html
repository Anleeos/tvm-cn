
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>NNPACK Contrib Installation &#8212; tvm-cn 1.0.0 文档</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/translations.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="Docker Images" href="docker.html" />
    <link rel="prev" title="从源码安装" href="from_source.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="nnpack-contrib-installation">
<h1>NNPACK Contrib Installation<a class="headerlink" href="#nnpack-contrib-installation" title="永久链接至标题">¶</a></h1>
<p><a class="reference external" href="https://github.com/Maratyszcza/NNPACK">NNPACK</a> is an acceleration package
for neural network computations, which can run on x86-64, ARMv7, or ARM64 architecture CPUs.
Using NNPACK, higher-level libraries like _MXNet_ can speed up
the execution on multi-core CPU computers, including laptops and mobile devices.</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>AS TVM already has natively tuned schedules, NNPACK is here mainly for reference and comparison purpose.
For regular use prefer native tuned TVM implementation.</p>
</div>
<p>TVM supports NNPACK for forward propagation (inference only) in convolution, max-pooling, and fully-connected layers.
In this document, we give a high level overview of how to use NNPACK with TVM.</p>
<div class="section" id="conditions">
<h2>Conditions<a class="headerlink" href="#conditions" title="永久链接至标题">¶</a></h2>
<p>The underlying implementation of NNPACK utilizes several acceleration methods,
including fft and winograd.
These algorithms work better on some special <cite>batch size</cite>, <cite>kernel size</cite>, and <cite>stride</cite> settings than on other,
so depending on the context, not all convolution, max-pooling, or fully-connected layers can be powered by NNPACK.
When favorable conditions for running NNPACKS are not met,</p>
<p>NNPACK only supports Linux and OS X systems. Windows is not supported at present.</p>
</div>
<div class="section" id="build-install-nnpack">
<h2>Build/Install NNPACK<a class="headerlink" href="#build-install-nnpack" title="永久链接至标题">¶</a></h2>
<p>If the trained model meets some conditions of using NNPACK,
you can build TVM with NNPACK support.
Follow these simple steps:</p>
<p>uild NNPACK shared library with the following commands. TVM will link NNPACK dynamically.</p>
<p>Note: The following NNPACK installation instructions have been tested on Ubuntu 16.04.</p>
<div class="section" id="build-ninja">
<h3>Build Ninja<a class="headerlink" href="#build-ninja" title="永久链接至标题">¶</a></h3>
<p>NNPACK need a recent version of Ninja. So we need to install ninja from source.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone git://github.com/ninja-build/ninja.git
<span class="nb">cd</span> ninja
./configure.py --bootstrap
</pre></div>
</div>
<p>Set the environment variable PATH to tell bash where to find the ninja executable. For example, assume we cloned ninja on the home directory ~. then we can added the following line in ~/.bashrc.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">PATH</span><span class="si">}</span><span class="s2">:~/ninja&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="build-nnpack">
<h3>Build NNPACK<a class="headerlink" href="#build-nnpack" title="永久链接至标题">¶</a></h3>
<p>The new CMAKE version of NNPACK download <a class="reference external" href="https://github.com/Maratyszcza/PeachPy">Peach</a> and other dependencies alone</p>
<p>Note: at least on OS X, running <cite>ninja install</cite> below will overwrite googletest libraries installed in <cite>/usr/local/lib</cite>. If you build googletest again to replace the nnpack copy, be sure to pass <cite>-DBUILD_SHARED_LIBS=ON</cite> to <cite>cmake</cite>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone --recursive https://github.com/Maratyszcza/NNPACK.git
<span class="nb">cd</span> NNPACK
<span class="c1"># Add PIC option in CFLAG and CXXFLAG to build NNPACK shared library</span>
sed -i <span class="s2">&quot;s|gnu99|gnu99 -fPIC|g&quot;</span> CMakeLists.txt
sed -i <span class="s2">&quot;s|gnu++11|gnu++11 -fPIC|g&quot;</span> CMakeLists.txt
mkdir build
<span class="nb">cd</span> build
<span class="c1"># Generate ninja build rule and add shared library in configuration</span>
cmake -G Ninja -D <span class="nv">BUILD_SHARED_LIBS</span><span class="o">=</span>ON ..
ninja
sudo ninja install

<span class="c1"># Add NNPACK lib folder in your ldconfig</span>
<span class="nb">echo</span> <span class="s2">&quot;/usr/local/lib&quot;</span> &gt; /etc/ld.so.conf.d/nnpack.conf
sudo ldconfig
</pre></div>
</div>
</div>
</div>
<div class="section" id="build-tvm-with-nnpack-support">
<h2>Build TVM with NNPACK support<a class="headerlink" href="#build-tvm-with-nnpack-support" title="永久链接至标题">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone --recursive https://github.com/apache/tvm tvm
</pre></div>
</div>
<ul class="simple">
<li><p>Set <cite>set(USE_NNPACK ON)</cite> in config.cmake.</p></li>
<li><p>Set <cite>NNPACK_PATH</cite> to the $(YOUR_NNPACK_INSTALL_PATH)</p></li>
</ul>
<p>after configuration use <cite>make</cite> to build TVM</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make
</pre></div>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">tvm-cn</a></h1>








<h3>导航</h3>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">安装 TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute/index.html">Contributor Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../how_to/index.html">How To Guides</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/how_to/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">Architecture Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption"><span class="caption-text">Topic Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">安装 TVM</a><ul>
  <li><a href="from_source.html">从源码安装</a><ul>
      <li>Previous: <a href="from_source.html" title="上一章">从源码安装</a></li>
      <li>Next: <a href="docker.html" title="下一章">Docker Images</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="转向" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, HyperAI.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/install/nnpack.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>